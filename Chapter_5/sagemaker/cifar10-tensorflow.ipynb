{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has been taken from AWS sample link below, and made some corrections to run successfully\n",
    "# https://aws.amazon.com/getting-started/hands-on/train-tune-deep-learning-model-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) use image \"Tensorflow 2.3 Python 3.7 GPU Optimized\" \n",
    "# (2) Install tensorflow so that the tensorflow version is 2.3.0 instead of 2.3.x, which is not compatiable with Sagemaker\n",
    "!pip install -U tensorflow==2.3.0\n",
    "import tensorflow as tf\n",
    "print(tf. __version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (1) under root folder /, create a new file named \"generate_cifar10_tfrecords.py\". first you have to choose text file which will \n",
    "# create untitled.txt, which has to be renamed as \"generate_cifar10_tfrecords.py\"\n",
    "\n",
    "# (2) Copy the code from below file path and put inside the newly created file \"generate_cifar10_tfrecords.py\" and save it.\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/utils/generate_cifar10_\n",
    "# tfrecords.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ipywidgets library\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helps to setup data directory for cifar10 dataset (tar.gz file from  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)\n",
    "!python generate_cifar10_tfrecords.py --data-dir cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-058199717680/datasets/cifar10-dataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, os, sys\n",
    "import sagemaker, boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "# get execution role\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "\n",
    "datasets = sagemaker_session.upload_data(path='cifar10', key_prefix='datasets/cifar10-dataset')\n",
    "datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "# change the experiment_name if needed. Experiment name has to be unique within and AWS account and AWS region\n",
    "training_experiment = Experiment.create(\n",
    "                                experiment_name = \"sagemaker-experiments-v1\", \n",
    "                                description     = \"Experiment to track cifar10 training trials\", \n",
    "                                sagemaker_boto_client=sm)\n",
    "########### set up trial\n",
    "\n",
    "l_experiment_name = training_experiment.experiment_name\n",
    "print(l_experiment_name)\n",
    "# Trial name should be unique\n",
    "single_gpu_trial = Trial.create(\n",
    "    trial_name = 'sagemaker-single-gpu-training-v1', \n",
    "    experiment_name = training_experiment.experiment_name,\n",
    "    sagemaker_boto_client = sm,\n",
    ")\n",
    "\n",
    "trial_comp_name = 'single-gpu-training-job'\n",
    "experiment_config = {\"ExperimentName\": training_experiment.experiment_name, \n",
    "                       \"TrialName\": single_gpu_trial.trial_name,\n",
    "                       \"TrialComponentDisplayName\": trial_comp_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.image.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "def get_dataset(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat().shuffle(10000)\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "def get_model(input_shape, learning_rate, weight_decay, optimizer, momentum):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = keras.applications.resnet50.ResNet50(include_top=False,\n",
    "                                                          weights='imagenet',\n",
    "                                                          input_tensor=input_tensor,\n",
    "                                                          input_shape=input_shape,\n",
    "                                                          classes=None)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Hyper-parameters\n",
    "    epochs       = 10\n",
    "    lr           = .01\n",
    "    batch_size   = 128\n",
    "    momentum     = 2e-4\n",
    "    weight_decay = 0.9\n",
    "    optimizer    = 'sgd'\n",
    "    model_dir = 's3://sagemaker-us-east-2-058199717680/models/cifar10/'\n",
    "\n",
    "    # SageMaker options\n",
    "    training_dir   = 's3://sagemaker-us-east-2-058199717680/datasets/cifar10-dataset'\n",
    "    validation_dir = 's3://sagemaker-us-east-2-058199717680/datasets/cifar10-dataset'\n",
    "    eval_dir       = 's3://sagemaker-us-east-2-058199717680/datasets/cifar10-dataset'\n",
    "    \n",
    "    \n",
    "    print(f\"training: {training_dir} | valid: {validation_dir} | eval: {eval_dir}\")\n",
    "    print(f\"optimizer: {optimizer}\")\n",
    "\n",
    "    train_dataset = get_dataset(training_dir+'/train.tfrecords',  batch_size)\n",
    "    val_dataset   = get_dataset(validation_dir+'/validation.tfrecords', batch_size)\n",
    "    eval_dataset  = get_dataset(eval_dir+'/eval.tfrecords', batch_size)\n",
    "    \n",
    "    input_shape = (HEIGHT, WIDTH, DEPTH)\n",
    "    model = get_model(input_shape, lr, weight_decay, optimizer, momentum)\n",
    "    \n",
    "    # Optimizer\n",
    "    if optimizer.lower() == 'sgd':\n",
    "        opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)\n",
    "    else:\n",
    "        opt = Adam(lr=lr, decay=weight_decay)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(train_dataset, steps_per_epoch=40000 // batch_size,\n",
    "                        validation_data=val_dataset, \n",
    "                        validation_steps=10000 // batch_size,\n",
    "                        epochs=epochs)\n",
    "                        \n",
    "    \n",
    "    # Evaluate model performance\n",
    "    score = model.evaluate(eval_dataset, steps=10000 // batch_size, verbose=1)\n",
    "    print('Test loss    :', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    # Save model to model directory\n",
    "    model.save(f'{model_dir}/{time.strftime(\"%m%d%H%M%S\", time.gmtime())}', save_format='tf')\n",
    "\n",
    "\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNE HYPERPARMETERS\n",
    "###################\n",
    "\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparams={'epochs'       : 30,\n",
    "             'learning-rate': 0.01,\n",
    "             'batch-size'   : 256,\n",
    "             'weight-decay' : 2e-4,\n",
    "             'momentum'     : 0.9,\n",
    "             'optimizer'    : 'adam'}\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "output_path = f's3://{bucket_name}/jobs'\n",
    "metric_definitions = [{'Name': 'val_acc', 'Regex': 'val_acc: ([0-9\\\\.]+)'}]\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point          = 'cifar10-training-sagemaker.py', \n",
    "                          output_path          = f'{output_path}/',\n",
    "                          code_location        = output_path,\n",
    "                          role                 = role,\n",
    "                          train_instance_count = 1, \n",
    "                          train_instance_type  = 'ml.g4dn.xlarge',\n",
    "                          framework_version    = '1.15.2', \n",
    "                          py_version           = 'py3',\n",
    "                          script_mode          = True,\n",
    "                          metric_definitions   = metric_definitions,\n",
    "                          sagemaker_session    = sagemaker_session,\n",
    "                          hyperparameters      = hyperparams)\n",
    "\n",
    "job_name=f'tensorflow-single-gpu-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "tf_estimator.fit({'training'  : datasets,\n",
    "                  'validation': datasets,\n",
    "                  'eval'      : datasets},\n",
    "                 job_name = job_name,\n",
    "                 experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training job\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparams={'epochs'       : 30,\n",
    "             'learning-rate': 0.01,\n",
    "             'batch-size'   : 256,\n",
    "             'weight-decay' : 2e-4,\n",
    "             'momentum'     : 0.9,\n",
    "             'optimizer'    : 'adam'}\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "output_path = f's3://{bucket_name}/jobs'\n",
    "metric_definitions = [{'Name': 'val_acc', 'Regex': 'val_acc: ([0-9\\\\.]+)'}]\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point          = 'cifar10-training-sagemaker-v2.py', \n",
    "                          output_path          = f'{output_path}/',\n",
    "                          code_location        = output_path,\n",
    "                          role                 = role,\n",
    "                          train_instance_count = 1, \n",
    "                          train_instance_type  = 'ml.g4dn.xlarge',\n",
    "                          framework_version    = '1.15.2', \n",
    "                          py_version           = 'py3',\n",
    "                          script_mode          = True,\n",
    "                          metric_definitions   = metric_definitions,\n",
    "                          sagemaker_session    = sagemaker_session,\n",
    "                          hyperparameters      = hyperparams)\n",
    "\n",
    "job_name=f'tensorflow-single-gpu-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "tf_estimator.fit({'training'  : datasets,\n",
    "                  'validation': datasets,\n",
    "                  'eval'      : datasets},\n",
    "                 job_name = job_name,\n",
    "                 experiment_config=experiment_config)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
