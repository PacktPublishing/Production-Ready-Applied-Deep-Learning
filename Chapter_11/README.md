### Deep Learning on Mobile Devices

In this chapter, we will introduce how to deploy TensorFlow (TF) and PyTorch models on mobile devices using TensorFlow Lite (TF Lite) and PyTorch Mobile, respectively.

* [Converting a TF model into a TF Lite model](https://www.tensorflow.org/lite/guide)
* [Converting a PyTorch model into a TorchScript model](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)
* [Running TF Lite model inference on iOS](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/swift)
* [Running TorchScript model inference on iOS](https://github.com/pytorch/ios-demo-app/tree/master/HelloWorld/HelloWorld/HelloWorld)
* [Running TF Lite model inference on Android](https://github.com/tensorflow/tflite-support/)
* [Running TorchScript model inference on Android](https://pytorch.org/mobile/android/)
 

#### Other useful resources
* [TorchScript](https://pytorch.org/docs/master/jit.html)
* [TF Lite inference](https://www.tensorflow.org/lite/guide/inference)
* [PyTorch in iOS](https://pytorch.org/mobile/ios/)
* [TF Lite Inference API](https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/Interpreter)
* [PyTorch Module documentation](https://pytorch.org/javadoc/1.4.0/org/pytorch/Module.html)
* [TF iOS quick start](https://www.tensorflow.org/lite/guide/ios)
* [TF android quick start](https://www.tensorflow.org/lite/android/quickstart)