{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494cc3bc",
   "metadata": {},
   "source": [
    "# Training deep learning model using PyTorch Lightning\n",
    "\n",
    "This example demonstrates Pytorch Lightning based model training.\n",
    "\n",
    "It's main focus is to show how the components described in `Implementing and training a model in PyTorch` section can be put together.\n",
    "\n",
    "Therefore model architecture and data processing is simplified that the trained model does not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487a244",
   "metadata": {},
   "source": [
    "## Data loading logics\n",
    "\n",
    "For this example, we will google scholar data that we crawled in Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f4c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a14fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sample_google_scholar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb76b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>email</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>coauthors_names</th>\n",
       "      <th>research_interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lawrence Holder</td>\n",
       "      <td>wsu.edu</td>\n",
       "      <td>Washington State University</td>\n",
       "      <td>Diane J Cook##William Eberle</td>\n",
       "      <td>artificial_intelligence##machine_learning##dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane J Cook</td>\n",
       "      <td>eecs.wsu.edu</td>\n",
       "      <td>Washington State University</td>\n",
       "      <td>Lawrence Holder##Parisa Rashidi##Sajal K. Das#...</td>\n",
       "      <td>artificial_intelligence##machine_learning##sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sumi Helal IEEE Fellow AAAS Fellow IET Fellow ...</td>\n",
       "      <td>cise.ufl.edu</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>Raja Bose##Darrell Woelk##Diane J Cook##Yousse...</td>\n",
       "      <td>digital_health##smart_homes##internet_of_thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hani Hagras</td>\n",
       "      <td>essex.ac.uk</td>\n",
       "      <td>University of Essex</td>\n",
       "      <td>Christian Wagner</td>\n",
       "      <td>explainable_artificial_intelligence##ambient_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anupam Joshi</td>\n",
       "      <td>umbc.edu</td>\n",
       "      <td>UMBC</td>\n",
       "      <td>Tim Finin##Yelena Yesha##Lalana Kagal##Dipanja...</td>\n",
       "      <td>data_management##mobile_computing##security##s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         author_name         email  \\\n",
       "0                                    Lawrence Holder       wsu.edu   \n",
       "3                                       Diane J Cook  eecs.wsu.edu   \n",
       "4  Sumi Helal IEEE Fellow AAAS Fellow IET Fellow ...  cise.ufl.edu   \n",
       "5                                        Hani Hagras   essex.ac.uk   \n",
       "6                                       Anupam Joshi      umbc.edu   \n",
       "\n",
       "                   affiliation  \\\n",
       "0  Washington State University   \n",
       "3  Washington State University   \n",
       "4        University of Florida   \n",
       "5          University of Essex   \n",
       "6                         UMBC   \n",
       "\n",
       "                                     coauthors_names  \\\n",
       "0                       Diane J Cook##William Eberle   \n",
       "3  Lawrence Holder##Parisa Rashidi##Sajal K. Das#...   \n",
       "4  Raja Bose##Darrell Woelk##Diane J Cook##Yousse...   \n",
       "5                                   Christian Wagner   \n",
       "6  Tim Finin##Yelena Yesha##Lalana Kagal##Dipanja...   \n",
       "\n",
       "                                   research_interest  \n",
       "0  artificial_intelligence##machine_learning##dat...  \n",
       "3  artificial_intelligence##machine_learning##sma...  \n",
       "4  digital_health##smart_homes##internet_of_thing...  \n",
       "5  explainable_artificial_intelligence##ambient_i...  \n",
       "6  data_management##mobile_computing##security##s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aff3ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33984375 0.37890625 0.44921875 0.40625    0.41015625 0.4296875\n",
      "  0.40234375 0.453125   0.43359375 0.4296875 ]\n",
      " [0.33984375 0.37890625 0.44921875 0.40625    0.41015625 0.4296875\n",
      "  0.40234375 0.453125   0.43359375 0.4296875 ]\n",
      " [0.33203125 0.4296875  0.41015625 0.4609375  0.39453125 0.4453125\n",
      "  0.44921875 0.41015625 0.453125   0.47265625]\n",
      " [0.33203125 0.4296875  0.41015625 0.4609375  0.39453125 0.4453125\n",
      "  0.44921875 0.41015625 0.453125   0.47265625]\n",
      " [0.33203125 0.30078125 0.2578125  0.26171875 0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# for features, we will convert first 10 characters of affiliation into a vector of float \n",
    "# by dividing each character by maximum axcii number (256)\n",
    "\n",
    "def convert_first_ten_characters_into_tensor(data):\n",
    "    first_ten_characters = data[:10]\n",
    "    converted = [ord(char)/256 for char in first_ten_characters]\n",
    "    while len(converted) < 10:\n",
    "        converted.append(0.0)\n",
    "    return np.array(converted)\n",
    "\n",
    "converted_affiliation = data['affiliation'].map(convert_first_ten_characters_into_tensor)\n",
    "affiliation = np.vstack(converted_affiliation.values)\n",
    "print(affiliation[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63f3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for labels, it will be boolean value; True if email consists of '.edu' and False otherwise\n",
    "\n",
    "converted_email = data['email'].str.contains('.edu')\n",
    "labels = converted_email.values\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e11bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from typing import Optional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SampleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.affiliation = torch.Tensor(affiliation)\n",
    "        self.labels = torch.Tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return number of samples\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"loads and returns a sample from the dataset at the given index\"\"\"\n",
    "        return self.affiliation[idx], int(self.labels[idx])\n",
    "\n",
    "\n",
    "class SampleDataModule(LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = 10\n",
    "        self.collate_fn = lambda x: x\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"download and preprocess the data; triggered only on single GPU\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"define necessary components for data loading on each GPU\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \"\"\"define train data loader\"\"\"\n",
    "        return DataLoader(\n",
    "            SampleDataset(),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"define validation data loader\"\"\"\n",
    "        return DataLoader(\n",
    "            SampleDataset(),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"define test data loader\"\"\"\n",
    "        return DataLoader(\n",
    "            SampleDataset(),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6aeec3",
   "metadata": {},
   "source": [
    "## Model definition & Model training \n",
    "\n",
    "For this example, we simply have three layers of fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb086a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch.optim.adam import Adam\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "\n",
    "class SampleModel(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define Network\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(10, 5),\n",
    "            nn.Linear(5, 3),\n",
    "            nn.Linear(3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # define loss function (BCELoss)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Feed input tensor to the networks and compute output\"\"\"\n",
    "        output_tensor = self.layers(x)\n",
    "        return output_tensor\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Define optimizer to use\"\"\"\n",
    "        return torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Define single training iteration\"\"\"\n",
    "        x, y = batch\n",
    "        # reformat targets for BCELoss\n",
    "        targets = y.unsqueeze(dim=1).to(torch.float32)\n",
    "        outputs = self(x)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Define single validation iteration\"\"\"\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Define single test iteration\"\"\"\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # reformat targets for BCELoss\n",
    "        targets = y.unsqueeze(dim=1).to(torch.float32)\n",
    "        outputs = self(x)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        acc = accuracy(outputs.round(), targets.int())\n",
    "        return loss, acc\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        \"\"\"Compute prediction for the given batch of data\"\"\"\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6444836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | layers    | Sequential | 77    \n",
      "1 | criterion | BCELoss    | 0     \n",
      "-----------------------------------------\n",
      "77        Trainable params\n",
      "0         Non-trainable params\n",
      "77        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:655: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e74cc41138d4b3da03de71b6ffd3f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# setup model training\n",
    "num_epochs = 10\n",
    "data_module = SampleDataModule()\n",
    "model = SampleModel()\n",
    "trainer = Trainer(max_epochs=num_epochs)\n",
    "\n",
    "# training a model\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66f450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59b15ce5d1b47ba97b4f2e96b6ace96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6333333253860474, 'test_loss': 0.6645503640174866}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "result = trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e29da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: True, prediction: True\n",
      "label: True, prediction: True\n",
      "label: True, prediction: True\n",
      "label: False, prediction: True\n",
      "label: True, prediction: True\n"
     ]
    }
   ],
   "source": [
    "# prediction using trained model\n",
    "model.eval()\n",
    "preds = model(torch.Tensor(affiliation[:5])).round()\n",
    "for label, pred in zip(labels[:5], preds):\n",
    "    print(f\"label: {label}, prediction: {bool(pred[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
