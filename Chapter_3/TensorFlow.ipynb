{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbd2cff-2ae6-48de-9366-ef9276b76851",
   "metadata": {},
   "source": [
    "# Training deep learning model using TensorFlow\n",
    "\n",
    "This example demonstrates TensorFlow based model training.\n",
    "\n",
    "It's main focus is to show how the components described in `Implementing and training a model in TensorFlow` section can be put together.\n",
    "\n",
    "Therefore model architecture and data processing is simplified that the trained model does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6230cd06-2990-40c7-b2df-62acdc5dde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "798bc3de-da36-4cd4-9936-a826600bf29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f0d7b95a-73ed-4311-a55e-87afb655951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1cb3d-e988-4a4b-af10-c68edf065572",
   "metadata": {},
   "source": [
    "## Data loading logics\n",
    "\n",
    "For this example, we will use google scholar data that we crawled in Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e498324b-5aef-4659-a1d6-222c750b07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sample_google_scholar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4a305055-2bd3-494b-a31e-c8fb7ba30aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>email</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>coauthors_names</th>\n",
       "      <th>research_interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lawrence Holder</td>\n",
       "      <td>wsu.edu</td>\n",
       "      <td>Washington State University</td>\n",
       "      <td>Diane J Cook##William Eberle</td>\n",
       "      <td>artificial_intelligence##machine_learning##dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane J Cook</td>\n",
       "      <td>eecs.wsu.edu</td>\n",
       "      <td>Washington State University</td>\n",
       "      <td>Lawrence Holder##Parisa Rashidi##Sajal K. Das#...</td>\n",
       "      <td>artificial_intelligence##machine_learning##sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sumi Helal IEEE Fellow AAAS Fellow IET Fellow ...</td>\n",
       "      <td>cise.ufl.edu</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>Raja Bose##Darrell Woelk##Diane J Cook##Yousse...</td>\n",
       "      <td>digital_health##smart_homes##internet_of_thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hani Hagras</td>\n",
       "      <td>essex.ac.uk</td>\n",
       "      <td>University of Essex</td>\n",
       "      <td>Christian Wagner</td>\n",
       "      <td>explainable_artificial_intelligence##ambient_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anupam Joshi</td>\n",
       "      <td>umbc.edu</td>\n",
       "      <td>UMBC</td>\n",
       "      <td>Tim Finin##Yelena Yesha##Lalana Kagal##Dipanja...</td>\n",
       "      <td>data_management##mobile_computing##security##s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         author_name         email  \\\n",
       "0                                    Lawrence Holder       wsu.edu   \n",
       "3                                       Diane J Cook  eecs.wsu.edu   \n",
       "4  Sumi Helal IEEE Fellow AAAS Fellow IET Fellow ...  cise.ufl.edu   \n",
       "5                                        Hani Hagras   essex.ac.uk   \n",
       "6                                       Anupam Joshi      umbc.edu   \n",
       "\n",
       "                   affiliation  \\\n",
       "0  Washington State University   \n",
       "3  Washington State University   \n",
       "4        University of Florida   \n",
       "5          University of Essex   \n",
       "6                         UMBC   \n",
       "\n",
       "                                     coauthors_names  \\\n",
       "0                       Diane J Cook##William Eberle   \n",
       "3  Lawrence Holder##Parisa Rashidi##Sajal K. Das#...   \n",
       "4  Raja Bose##Darrell Woelk##Diane J Cook##Yousse...   \n",
       "5                                   Christian Wagner   \n",
       "6  Tim Finin##Yelena Yesha##Lalana Kagal##Dipanja...   \n",
       "\n",
       "                                   research_interest  \n",
       "0  artificial_intelligence##machine_learning##dat...  \n",
       "3  artificial_intelligence##machine_learning##sma...  \n",
       "4  digital_health##smart_homes##internet_of_thing...  \n",
       "5  explainable_artificial_intelligence##ambient_i...  \n",
       "6  data_management##mobile_computing##security##s...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "57cf9628-c855-4b46-b41f-0fdee4361f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33984375 0.37890625 0.44921875 0.40625    0.41015625 0.4296875\n",
      "  0.40234375 0.453125   0.43359375 0.4296875 ]\n",
      " [0.33984375 0.37890625 0.44921875 0.40625    0.41015625 0.4296875\n",
      "  0.40234375 0.453125   0.43359375 0.4296875 ]\n",
      " [0.33203125 0.4296875  0.41015625 0.4609375  0.39453125 0.4453125\n",
      "  0.44921875 0.41015625 0.453125   0.47265625]\n",
      " [0.33203125 0.4296875  0.41015625 0.4609375  0.39453125 0.4453125\n",
      "  0.44921875 0.41015625 0.453125   0.47265625]\n",
      " [0.33203125 0.30078125 0.2578125  0.26171875 0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# for features, we will convert first 10 characters of affiliation into a vector of float \n",
    "# by dividing each character by maximum axcii number (256)\n",
    "\n",
    "def convert_first_ten_characters_into_tensor(data):\n",
    "    first_ten_characters = data[:10]\n",
    "    converted = [ord(char)/256 for char in first_ten_characters]\n",
    "    while len(converted) < 10:\n",
    "        converted.append(0.0)\n",
    "    return np.array(converted)\n",
    "\n",
    "converted_affiliation = data['affiliation'].map(convert_first_ten_characters_into_tensor)\n",
    "affiliation = np.vstack(converted_affiliation.values)\n",
    "print(affiliation[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "486bc9ee-667a-4afb-a29e-08c137ba1b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for labels, it will be boolean value; True if email consists of '.edu' and False otherwise\n",
    "converted_email = data['email'].str.contains('.edu')\n",
    "labels = converted_email.values\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717f87c-3267-45d0-b504-603576a0bbf6",
   "metadata": {},
   "source": [
    "### This concludes this simple preprocessing step. As result, we have features (called affiliation) and labels\n",
    "In real life, this could be a separate processing job executed for example via spark job. \n",
    "Let's save those results as csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e3e65bb-fb46-4ad0-b3ef-bf22f4074a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.339844  0.378906  0.449219  0.406250  0.410156  0.429688  0.402344   \n",
       "1  0.339844  0.378906  0.449219  0.406250  0.410156  0.429688  0.402344   \n",
       "2  0.332031  0.429688  0.410156  0.460938  0.394531  0.445312  0.449219   \n",
       "3  0.332031  0.429688  0.410156  0.460938  0.394531  0.445312  0.449219   \n",
       "4  0.332031  0.300781  0.257812  0.261719  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7         8         9      10  \n",
       "0  0.453125  0.433594  0.429688   True  \n",
       "1  0.453125  0.433594  0.429688   True  \n",
       "2  0.410156  0.453125  0.472656   True  \n",
       "3  0.410156  0.453125  0.472656  False  \n",
       "4  0.000000  0.000000  0.000000   True  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([pd.DataFrame(affiliation),pd.DataFrame(labels)],axis=1, ignore_index=True)\n",
    "full_df.to_csv('data.csv', index=False, header=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b030e6-5237-489d-88bc-752a4c4f4624",
   "metadata": {},
   "source": [
    "We can also transform this pandas dataframe to two columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "19fd782b-610a-4e8d-ada2-fd2f60e7a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['labels'] = full_df.iloc[: , -1].values\n",
    "full_df['features']= full_df.iloc[: , :-2].values.tolist()\n",
    "for i in range(11):\n",
    "    full_df.pop(i)\n",
    "full_df.to_csv('data_2c.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f608433b-3c9e-48cb-b297-b7f80aebb311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.33984375, 0.37890625, 0.44921875, 0.40625, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.33984375, 0.37890625, 0.44921875, 0.40625, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.33203125, 0.4296875, 0.41015625, 0.4609375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[0.33203125, 0.4296875, 0.41015625, 0.4609375,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[0.33203125, 0.30078125, 0.2578125, 0.26171875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                           features\n",
       "0    True  [0.33984375, 0.37890625, 0.44921875, 0.40625, ...\n",
       "1    True  [0.33984375, 0.37890625, 0.44921875, 0.40625, ...\n",
       "2    True  [0.33203125, 0.4296875, 0.41015625, 0.4609375,...\n",
       "3   False  [0.33203125, 0.4296875, 0.41015625, 0.4609375,...\n",
       "4    True  [0.33203125, 0.30078125, 0.2578125, 0.26171875..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "05ee9e85-6f9a-4220-ad79-cc89567abc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4fed3cce-fb6e-4f68-aa83-89297245b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['path'] = \"data.csv\"\n",
    "config['path_2c'] = \"data_2c.csv\"\n",
    "config['tfds_dataset'] = \"mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "62917609-386b-473d-beef-02f262929469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\n"
     ]
    }
   ],
   "source": [
    "print(config.get('path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f2e0a710-1777-4ead-88a6-12d79a052a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader: \n",
    "    \"\"\" DataLoader class\"\"\"\n",
    "    @staticmethod \n",
    "    def load_data_tfds(config): \n",
    "        '''\n",
    "        loads predifined datset from tfds \n",
    "        '''\n",
    "        print(config.get('tfds_dataset'))\n",
    "        return tfds.load(config.get('tfds_dataset'), split=tfds.Split.TRAIN, as_supervised=\"True\")\n",
    "    \n",
    "    @staticmethod \n",
    "    def load_data_csv(config, tag, batch_size, label_name, select_columns): \n",
    "        '''\n",
    "        loads predifined datset from tfds \n",
    "        '''\n",
    "        return tf.data.experimental.make_csv_dataset(config.get(tag), \n",
    "                                                     batch_size=batch_size,\n",
    "                                                     label_name=label_name,\n",
    "                                                     select_columns=select_columns)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data_from_nump_arrays(feature, label):\n",
    "        '''\n",
    "        loads data from numpy to tf.data.Dataset\n",
    "        '''\n",
    "        return tf.data.Dataset.from_tensor_slices( (feature, label) )\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data_from_pandas(df):\n",
    "        '''\n",
    "        loads data from pandas to tf.data.Dataset\n",
    "        '''\n",
    "        return tf.data.Dataset.from_tensor_slices((df.iloc[: , :-1].values, df.iloc[: , -1].values))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e2b7ad-cc18-4089-902f-ee0a79e6ee23",
   "metadata": {},
   "source": [
    "### Let's start with loading data from csv\n",
    "We have prepared two versions: \n",
    "1. csv with two columns \n",
    "2. csv with 10 columns\n",
    "Let's start with first point, and then look at the second one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8f3b5f7f-147f-42d7-8d39-7739e5186702",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'labels'\n",
    "select_columns = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "509a18f9-68f9-43fa-a8b5-a88dd4bc2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader().load_data_csv(config, 'path_2c', 1, label_name, select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "636dac69-f49d-40a4-a2e9-bb3095e45af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(OrderedDict([('features', TensorSpec(shape=(1,), dtype=tf.string, name=None))]), TensorSpec(shape=(1,), dtype=tf.string, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b986c1f-d382-463b-9814-288873fa1f9e",
   "metadata": {},
   "source": [
    "In this case, we see that our feature column is saved as a single tensor of shape (1,) that holds our feature arrays as string representations. Therefore, some additional processing might be required to use that dataset. The `map` method can be used in this situation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "07193b6a-db25-4a16-ad44-a603288b5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: (OrderedDict([('features', <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'[0.3046875, 0.39453125, 0.46484375, 0.125, 0.34765625, 0.43359375, 0.4453125, 0.41796875, 0.125, 0.28515625]'],\n",
      "      dtype=object)>)]), <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'True'], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "for feature in data.take(1):\n",
    "    print('Tensor:',feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eda2ed-81d3-4764-9aea-5d7213d67188",
   "metadata": {},
   "source": [
    "Let's move on to the second csv file case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a203334d-0b2c-421f-aac3-c79f2caba3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = '10'\n",
    "select_columns = range(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "909785f2-9695-473e-8606-a7de05f16bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader().load_data_csv(config, 'path', 1, label_name, select_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c748bdf5-7617-49e2-adff-82b50d3c4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(OrderedDict([('0', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('1', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('2', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('3', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('4', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('5', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('6', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('7', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('8', TensorSpec(shape=(1,), dtype=tf.float32, name=None)), ('9', TensorSpec(shape=(1,), dtype=tf.float32, name=None))]), TensorSpec(shape=(1,), dtype=tf.string, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7436aa9-4eed-4153-8a17-dce84be68ee2",
   "metadata": {},
   "source": [
    "We can use `map` method to transfor this dataset to a desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "16ac214e-c013-4bbc-ba56-087dba486d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(samples, labels):\n",
    "    return [ x for x in list(samples.values()) ], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "60e04e7a-d40b-4ae0-86c3-e0b5025da693",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.map(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ff527380-98b7-4d2e-89e3-b056e07ebc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(1, 1), dtype=tf.string, name=None), TensorSpec(shape=(1,), dtype=tf.string, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9f58c64b-0be4-41dd-ac8a-3ef2c3bb421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: (<tf.Tensor: shape=(1, 1), dtype=string, numpy=\n",
      "array([[b'[0.3046875, 0.43359375, 0.4453125, 0.453125, 0.40625, 0.46484375, 0.39453125, 0.44921875, 0.453125, 0.39453125]']],\n",
      "      dtype=object)>, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'True'], dtype=object)>)\n"
     ]
    }
   ],
   "source": [
    "for feature in dataset.take(1):\n",
    "    print('Tensor:',feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342668e-f1b2-466a-8cac-03946c5f8118",
   "metadata": {},
   "source": [
    "Now, we can see how to load tfds datset. In this example we will load mnist dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a986c836-a6df-4e99-9951-c2e8287c4d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader().load_data_tfds(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6493e4ae-0049-4b5d-b990-6061fe7629ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccea4af-6d01-41cd-9cd8-06664faada1f",
   "metadata": {},
   "source": [
    "Let's see how we can create a dataset using numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a811dddb-b291-439a-8673-61bfe92302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader().load_data_from_nump_arrays(affiliation, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "81ae0e02-d4c1-40d6-bb71-6eba44d1715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=(TensorSpec(shape=(10,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.bool, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ccf88-0d49-46ab-a8b3-c06578dfcd35",
   "metadata": {},
   "source": [
    "Finally, we can create datset using pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "65c90f45-8603-4ebe-b885-5e91c93ae6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.378906</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>0.410156</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.261719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.339844  0.378906  0.449219  0.406250  0.410156  0.429688  0.402344   \n",
       "1  0.339844  0.378906  0.449219  0.406250  0.410156  0.429688  0.402344   \n",
       "2  0.332031  0.429688  0.410156  0.460938  0.394531  0.445312  0.449219   \n",
       "3  0.332031  0.429688  0.410156  0.460938  0.394531  0.445312  0.449219   \n",
       "4  0.332031  0.300781  0.257812  0.261719  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7         8         9      10  \n",
       "0  0.453125  0.433594  0.429688   True  \n",
       "1  0.453125  0.433594  0.429688   True  \n",
       "2  0.410156  0.453125  0.472656   True  \n",
       "3  0.410156  0.453125  0.472656  False  \n",
       "4  0.000000  0.000000  0.000000   True  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat([pd.DataFrame(affiliation),pd.DataFrame(labels)],axis=1, ignore_index=True)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6de1f07f-11d3-48a7-ad29-2e9064ba44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader().load_data_from_pandas(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d7d8da5a-8619-43a4-b3dd-a9f02ed3f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=(TensorSpec(shape=(10,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.bool, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f98624d8-c652-4d53-82b9-21e5e6c0e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: (<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
      "array([0.33984375, 0.37890625, 0.44921875, 0.40625   , 0.41015625,\n",
      "       0.4296875 , 0.40234375, 0.453125  , 0.43359375, 0.4296875 ])>, <tf.Tensor: shape=(), dtype=bool, numpy=True>)\n"
     ]
    }
   ],
   "source": [
    "for feature in data.take(1):\n",
    "    print('Tensor:',feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f237eda-716e-4dda-92a1-f6593f8dd7ec",
   "metadata": {},
   "source": [
    "Next, let's have a look option that is using python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "10923cf0-6086-4881-8efb-235bfd8c8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33984375 0.37890625 0.44921875 0.40625    0.41015625 0.4296875\n",
      " 0.40234375 0.453125   0.43359375 0.4296875 ]\n"
     ]
    }
   ],
   "source": [
    "print( affiliation[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "13627a5a-4d82-4823-afeb-563eb2619be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print( labels[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ae980671-0f85-4533-b9d9-bd13697e7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(affiliation, labels): \n",
    "    def fetch_examples(): \n",
    "        i = 0 \n",
    "        while True: \n",
    "            example = (affiliation[i], labels[i]) \n",
    "            i += 1 \n",
    "            i %= len(labels) \n",
    "            yield example \n",
    "    return fetch_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f4f3ada8-437a-4f75-ae18-2998019bc6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "features_shape = 10\n",
    "\n",
    "dataset_gen = tf.data.Dataset.from_generator(data_generator(affiliation, labels), \n",
    "                                                  output_types=(tf.float32, tf.bool), \n",
    "                                                  output_shapes=(tf.TensorShape(features_shape,), \n",
    "                                                                 tf.TensorShape(None))).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a8a61ff0-6cb5-4c08-addb-c54b6995783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: (<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
      "array([[0.33984375, 0.37890625, 0.44921875, 0.40625   , 0.41015625,\n",
      "        0.4296875 , 0.40234375, 0.453125  , 0.43359375, 0.4296875 ],\n",
      "       [0.33984375, 0.37890625, 0.44921875, 0.40625   , 0.41015625,\n",
      "        0.4296875 , 0.40234375, 0.453125  , 0.43359375, 0.4296875 ],\n",
      "       [0.33203125, 0.4296875 , 0.41015625, 0.4609375 , 0.39453125,\n",
      "        0.4453125 , 0.44921875, 0.41015625, 0.453125  , 0.47265625],\n",
      "       [0.33203125, 0.4296875 , 0.41015625, 0.4609375 , 0.39453125,\n",
      "        0.4453125 , 0.44921875, 0.41015625, 0.453125  , 0.47265625],\n",
      "       [0.33203125, 0.30078125, 0.2578125 , 0.26171875, 0.        ,\n",
      "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(5,), dtype=bool, numpy=array([ True,  True,  True, False,  True])>)\n"
     ]
    }
   ],
   "source": [
    "for feature in dataset_gen.take(1):\n",
    "    print('Tensor:',feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1229f-1e93-4fcc-a307-24761faa834f",
   "metadata": {},
   "source": [
    "## Model creation \n",
    "1. Model definition based on `tf.keras.Sequential` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b3d64c4f-0358-40fa-b4b2-c1c3948f1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "input_shape = 10\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\", name=\"layer3\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "02084f99-302a-449b-9637-35ed659629d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 128)               1408      \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 64)                8256      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b3b07-a54c-4c49-9f39-b2cb427704bd",
   "metadata": {},
   "source": [
    "2. Model definition based on `keras.Model` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "34d30976-2429-4ef9-8660-a4efff6bb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(10, name=\"input_layer\")\n",
    "x_1 = layers.Dense(128, activation=\"relu\", name=\"layer1\")(input_layer)\n",
    "x_2 = layers.Dense(64, activation=\"relu\", name=\"layer2\")(x_1)\n",
    "x_3 = layers.Dense(1, activation=\"sigmoid\", name=\"layer3\")(x_2)\n",
    "model2 = keras.Model( input_layer, x_3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d155867a-3493-466d-8ef5-81b89e841911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 10)]              0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 128)               1408      \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 64)                8256      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a512e-cffb-45d5-bf4d-89d84a0287f4",
   "metadata": {},
   "source": [
    "3. The third option is to create a class that inherits `keras.Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "61bdd6e2-a6bd-454b-a75f-80312f0b5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_1 = layers.Dense(128, activation=\"relu\", name=\"layer1\")\n",
    "        self.dense_2 = layers.Dense(64, activation=\"relu\", name=\"layer2\")\n",
    "        self.out =  layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        return self.out(x)\n",
    "    def build_graph(self, raw_shape):\n",
    "        x = tf.keras.layers.Input(shape=raw_shape)\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9dd3993a-ae63-423c-9d57-e1a6b458b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SimpleANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "958e2b97-e7c8-4d80-ac79-79a4793e9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = model3.build_graph(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b857a35a-8bcd-4c64-a3c1-3ab2188d19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 10)]              0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 128)               1408      \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 64)                8256      \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954be638-a7f6-4038-9d9b-e7e6476a7907",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "First of all, you need to compile your model and provide optimizer and loss function. \n",
    "In our example, we will use Adam optimizer and Binary Cross Entropy loss function as we are trying to solve binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "07095b3e-f349-47c3-9f23-a4cea0919bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7a2c05c4-6131-444e-b969-cdf96314a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "8e586565-3a02-4fe4-b982-4d606ae2b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b2223ebc-b046-4b7c-a87e-5749aaf2ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "90e23412-50cd-41dd-9a3f-54b4aed5f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2718c3-5637-4891-ac34-d03554c730c6",
   "metadata": {},
   "source": [
    "### Start training\n",
    "Using numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ee970026-7f35-448d-93d6-e80976d667b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6740 - val_loss: 0.7133\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6711 - val_loss: 0.7129\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6696 - val_loss: 0.7099\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6672 - val_loss: 0.7079\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6655 - val_loss: 0.7083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86cee6d060>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1b418e05-2bab-466b-8908-72119612fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.6960 - val_loss: 0.6986\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6944 - val_loss: 0.7171\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6906 - val_loss: 0.7254\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6881 - val_loss: 0.7216\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6862 - val_loss: 0.7196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86cc51bfd0>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "bf804ec0-3e47-45b8-a66a-ae1bcf3d3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6997 - val_loss: 0.7321\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6900 - val_loss: 0.7249\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6868 - val_loss: 0.7126\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6848 - val_loss: 0.7018\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6820 - val_loss: 0.7006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86ce4e2650>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f882a6-439c-4a02-9649-4697bac3c8d9",
   "metadata": {},
   "source": [
    "Train model using `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a902a08e-d624-4517-a289-20c9e031cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader().load_data_from_nump_arrays(affiliation, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "50bc1b4b-069b-46a0-84ee-0a36628b11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.shuffle(buffer_size=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "5e9a3eff-58c0-4466-b6f3-08edc2fc4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "fe4a639e-1962-450b-b917-7759c717b758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6134\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6094\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6056\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6043\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86cde51ed0>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95b06d-2e77-4ece-80cc-9974508fdae4",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "b8b3fcef-18c7-4f02-8e67-a05c527371df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_huber_loss(threshold=1.0): \n",
    "    def huber_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "ca9ec57f-0172-48e0-81e1-00b55c88ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=custom_huber_loss(2.0), optimizer=\"adam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "4258351f-b5f8-4e2e-9044-f362a0b7ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 128)               1408      \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 64)                8256      \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "b870d3f7-3a19-4c53-ada5-51a201c466ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 76ms/step - loss: 0.1029 - mae: 0.4406 - val_loss: 0.1310 - val_mae: 0.4954\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1007 - mae: 0.4351 - val_loss: 0.1267 - val_mae: 0.4878\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0999 - mae: 0.4341 - val_loss: 0.1172 - val_mae: 0.4697\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0989 - mae: 0.4323 - val_loss: 0.1184 - val_mae: 0.4713\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0983 - mae: 0.4303 - val_loss: 0.1203 - val_mae: 0.4744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86bfdf31f0>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120070f6-adc8-4ed3-be1b-cf7a3a25be76",
   "metadata": {},
   "source": [
    "Another option is to create a class that inherits `tf.keras.losses.Loss` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "96e9c726-3e1b-4ab0-ad4f-aef98365b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        error = y_true - y_pred \n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2 \n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2 \n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "07d1dc2f-a4c9-4ac5-b87c-87494f8a26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_custom = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "655d87e6-0c24-4be4-afe8-ec56cdc35ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss_custom, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "69186f01-58f2-44cb-bca6-a6ba7c37f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 73ms/step - loss: 0.0982 - mae: 0.4249 - val_loss: 0.1360 - val_mae: 0.4995\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0954 - mae: 0.4184 - val_loss: 0.1171 - val_mae: 0.4644\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0981 - mae: 0.4255 - val_loss: 0.1109 - val_mae: 0.4509\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0958 - mae: 0.4197 - val_loss: 0.1160 - val_mae: 0.4608\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0969 - mae: 0.4222 - val_loss: 0.1306 - val_mae: 0.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86bbd9ab00>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16217676-f95f-458b-93d5-164954734bd2",
   "metadata": {},
   "source": [
    "## TensorFlow Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "21742eef-ec7e-4908-828b-85bd7c16bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.1, patience=2, verbose=0,\n",
    "    mode='min', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "6f215a51-9bac-467d-9e60-964ea940d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0948 - mae: 0.4153 - val_loss: 0.1338 - val_mae: 0.4930\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0954 - mae: 0.4165 - val_loss: 0.1251 - val_mae: 0.4770\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0934 - mae: 0.4126 - val_loss: 0.1250 - val_mae: 0.4763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86b82e01f0>"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(affiliation, labels, batch_size=16, epochs=5, validation_split=0.2, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6b99c-52e6-44d7-851e-1ed754d8e52a",
   "metadata": {},
   "source": [
    "## Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "b41f39b3-2c8a-46b4-9c6c-7ea0d2d8fe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 loss: 0.6113289\n",
      "Binary Accuracy:  0.7135416865348816\n",
      "epoch : 2 loss: 0.49480128\n",
      "Binary Accuracy:  0.734375\n",
      "epoch : 3 loss: 0.46449468\n",
      "Binary Accuracy:  0.7239583134651184\n",
      "epoch : 4 loss: 0.37761664\n",
      "Binary Accuracy:  0.7239583134651184\n",
      "epoch : 5 loss: 0.6014573\n",
      "Binary Accuracy:  0.7135416865348816\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "BinaryAccuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "epochs = 5 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_ = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        BinaryAccuracy.update_state(y_batch_train, logits)\n",
    "    print(\"epoch : \" + str(epoch+1) + \" loss: \" + str(loss_.numpy()) ) \n",
    "    Acc = BinaryAccuracy.result()\n",
    "    print( \"Binary Accuracy: \", float(Acc) )\n",
    "    BinaryAccuracy.reset_states() #reset states after each epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac3d26-f884-458d-9b39-3b21d2058a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
